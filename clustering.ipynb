{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:11.337241Z",
     "iopub.execute_input": "2022-03-18T02:56:11.337716Z",
     "iopub.status.idle": "2022-03-18T02:56:11.373382Z",
     "shell.execute_reply.started": "2022-03-18T02:56:11.337545Z",
     "shell.execute_reply": "2022-03-18T02:56:11.372488Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "customer = pd.read_csv(\"../input/100honch4/customer_join.csv\")\n",
    "uselog = pd.read_csv(\"../input/100honch4/use_log.csv\")\n",
    "customer.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:11.375181Z",
     "iopub.execute_input": "2022-03-18T02:56:11.376084Z",
     "iopub.status.idle": "2022-03-18T02:56:11.689658Z",
     "shell.execute_reply.started": "2022-03-18T02:56:11.37604Z",
     "shell.execute_reply": "2022-03-18T02:56:11.688818Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "uselog.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:11.690892Z",
     "iopub.execute_input": "2022-03-18T02:56:11.691109Z",
     "iopub.status.idle": "2022-03-18T02:56:11.701358Z",
     "shell.execute_reply.started": "2022-03-18T02:56:11.691083Z",
     "shell.execute_reply": "2022-03-18T02:56:11.700734Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "uselog.isnull().sum()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:11.703778Z",
     "iopub.execute_input": "2022-03-18T02:56:11.704055Z",
     "iopub.status.idle": "2022-03-18T02:56:11.779391Z",
     "shell.execute_reply.started": "2022-03-18T02:56:11.704022Z",
     "shell.execute_reply": "2022-03-18T02:56:11.778556Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "customer.isnull().sum()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:11.780747Z",
     "iopub.execute_input": "2022-03-18T02:56:11.781078Z",
     "iopub.status.idle": "2022-03-18T02:56:11.794249Z",
     "shell.execute_reply.started": "2022-03-18T02:56:11.781042Z",
     "shell.execute_reply": "2022-03-18T02:56:11.793617Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "customer_clustering = customer[[\"mean\", \"median\", \"max\", \"min\", \"membership_period\"]]\n",
    "customer_clustering.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:11.79531Z",
     "iopub.execute_input": "2022-03-18T02:56:11.795711Z",
     "iopub.status.idle": "2022-03-18T02:56:11.81443Z",
     "shell.execute_reply.started": "2022-03-18T02:56:11.795677Z",
     "shell.execute_reply": "2022-03-18T02:56:11.813803Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#libraries to implement K-means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#create an object \"StandardScaler()\" from sklearn.preprocessing\n",
    "#StandardScaler() is to standardilize datas\n",
    "#fit_transform: calculate parameters and transform datas at the same time to standardise them.\n",
    "#standardilizationo : Data transformation with a mean of zero and variance of one\n",
    "\n",
    "sc = StandardScaler()\n",
    "customer_clustering_sc = sc.fit_transform(customer_clustering)\n",
    "\n",
    "#build models of K-means\n",
    "kmeans = KMeans(n_clusters=4, random_state=0)\n",
    "\n",
    "#embedding standardised data in the fabric of the generated model\n",
    "clusters = kmeans.fit(customer_clustering_sc)\n",
    "\n",
    "#labelling the generated n_clusters clusters\n",
    "customer_clustering[\"cluster\"] = clusters.labels_\n",
    "\n",
    "print(customer_clustering[\"cluster\"].unique())\n",
    "customer_clustering.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:11.815801Z",
     "iopub.execute_input": "2022-03-18T02:56:11.816205Z",
     "iopub.status.idle": "2022-03-18T02:56:14.579034Z",
     "shell.execute_reply.started": "2022-03-18T02:56:11.816172Z",
     "shell.execute_reply": "2022-03-18T02:56:14.578037Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "customer_clustering.columns= [\"月内平均値\", \"月内中央値\", \"月内最大値\", \"月内最小値\", \"会員期間\", \"cluster\"]\n",
    "\n",
    "#count():　functions to aggregate data\n",
    "customer_clustering.groupby(\"cluster\").count()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:14.580465Z",
     "iopub.execute_input": "2022-03-18T02:56:14.580807Z",
     "iopub.status.idle": "2022-03-18T02:56:14.595995Z",
     "shell.execute_reply.started": "2022-03-18T02:56:14.580765Z",
     "shell.execute_reply": "2022-03-18T02:56:14.594913Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "customer_clustering.groupby(\"cluster\").mean()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:14.597167Z",
     "iopub.execute_input": "2022-03-18T02:56:14.597968Z",
     "iopub.status.idle": "2022-03-18T02:56:14.616191Z",
     "shell.execute_reply.started": "2022-03-18T02:56:14.597921Z",
     "shell.execute_reply": "2022-03-18T02:56:14.615602Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#Library for principal component analysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Fabric of models for principal component analysis.\n",
    "pca = PCA(n_components = 2)\n",
    "X = customer_clustering_sc\n",
    "\n",
    "#Perform principal component analysis.\n",
    "pca.fit(X)\n",
    "x_pca = pca.transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(x_pca)\n",
    "pca_df[\"cluster\"] = customer_clustering[\"cluster\"]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:14.618162Z",
     "iopub.execute_input": "2022-03-18T02:56:14.618656Z",
     "iopub.status.idle": "2022-03-18T02:56:14.650772Z",
     "shell.execute_reply.started": "2022-03-18T02:56:14.618619Z",
     "shell.execute_reply": "2022-03-18T02:56:14.649719Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for i in customer_clustering[\"cluster\"].unique():\n",
    "    tmp = pca_df.loc[pca_df[\"cluster\"]==i]\n",
    "    plt.scatter(tmp[0], tmp[1])\n",
    "\n",
    "customer_clustering = pd.concat([customer_clustering, customer], axis=1)\n",
    "customer_clustering.head()\n",
    "\n",
    "customer_clustering.groupby([\"cluster\", \"is_deleted\"], as_index=False).count()[[\"cluster\", \"is_deleted\", \"customer_id\"]]\n",
    "customer_clustering.groupby([\"cluster\", \"routine_flg\"], as_index=False).count()[[\"cluster\", \"routine_flg\", \"customer_id\"]]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T02:56:14.652244Z",
     "iopub.execute_input": "2022-03-18T02:56:14.652835Z",
     "iopub.status.idle": "2022-03-18T02:56:14.992657Z",
     "shell.execute_reply.started": "2022-03-18T02:56:14.652783Z",
     "shell.execute_reply": "2022-03-18T02:56:14.991645Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Use supervised learning regression to make predictions.\n",
    "\n",
    "uselog[\"usedate\"] = pd.to_datetime(uselog[\"usedate\"])\n",
    "uselog[\"年月\"] = uselog[\"usedate\"].dt.strftime(\"%Y%m\")\n",
    "uselog_months = uselog.groupby([\"年月\", \"customer_id\"], as_index = False).count()\n",
    "uselog_months.head()\n",
    "uselog_months.rename(columns={\"log_id\":\"count\"}, inplace=True)\n",
    "del uselog_months[\"usedate\"]\n",
    "uselog_months.head()\n",
    "\n",
    "year_months = list(uselog_months[\"年月\"].unique())　#unique(): retrieve only the types that exist\n",
    "predict_data = pd.DataFrame() #Create empty data frames.\n",
    "\n",
    "for i in range((int)((len(year_months)+1)/2), len(year_months)): #Extract the most recent half of the data\n",
    "    \n",
    "    tmp = uselog_months.loc[uselog_months[\"年月\"] == year_months[i]]\n",
    "    tmp.rename(columns={\"count\":\"count_pred\"}, inplace=True)　#From frequency to predicted frequency\n",
    "    \n",
    "    for j in range(1,7): #training is carried out on the last six months of data\n",
    "        tmp_before = uselog_months.loc[uselog_months[\"年月\"]==year_months[i-j]]\n",
    "        del tmp_before[\"年月\"]\n",
    "        tmp_before.rename(columns={\"count\": \"count_{}\".format(j-1)}, inplace=True)\n",
    "        tmp = pd.merge(tmp, tmp_before, on=\"customer_id\", how=\"left\")\n",
    "        \n",
    "    predict_data = pd.concat([predict_data, tmp], ignore_index=True) #Use pd.concat for vertical connections\n",
    "    \n",
    "predict_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "predict_data = predict_data.dropna() #Removal of data containing NaN\n",
    "predict_data = predict_data.reset_index(drop=True) #restore index\n",
    "predict_data.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T03:15:25.401169Z",
     "iopub.execute_input": "2022-03-18T03:15:25.40151Z",
     "iopub.status.idle": "2022-03-18T03:15:25.428965Z",
     "shell.execute_reply.started": "2022-03-18T03:15:25.401465Z",
     "shell.execute_reply": "2022-03-18T03:15:25.428047Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predict_data = pd.merge(predict_data, customer[[\"customer_id\", \"start_date\"]], on=\"customer_id\", how=\"left\")\n",
    "predict_data.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T03:16:21.078879Z",
     "iopub.execute_input": "2022-03-18T03:16:21.079147Z",
     "iopub.status.idle": "2022-03-18T03:16:21.109301Z",
     "shell.execute_reply.started": "2022-03-18T03:16:21.07912Z",
     "shell.execute_reply": "2022-03-18T03:16:21.108545Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predict_data[\"now_date\"] = pd.to_datetime(predict_data[\"年月\"], format=\"%Y%m\")\n",
    "predict_data[\"start_date\"] = pd.to_datetime(predict_data[\"start_date\"])\n",
    "\n",
    "from dateutil.relativedelta import relativedelta #use relativedelta to take the difference between years and months\n",
    "predict_data[\"period\"] = 0\n",
    "\n",
    "for i in range(len(predict_data)): \n",
    "    delta = relativedelta(predict_data[\"now_date\"][i], predict_data[\"start_date\"][i])\n",
    "    predict_data[\"period\"][i] = delta.years*12 + delta.months\n",
    "    \n",
    "predict_data.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T03:23:58.249712Z",
     "iopub.execute_input": "2022-03-18T03:23:58.250007Z",
     "iopub.status.idle": "2022-03-18T03:24:04.607932Z",
     "shell.execute_reply.started": "2022-03-18T03:23:58.249979Z",
     "shell.execute_reply": "2022-03-18T03:24:04.607037Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "predict_data = predict_data.loc[predict_data[\"start_date\"] >= pd.to_datetime(\"20180401\")]\n",
    "\n",
    "from sklearn import linear_model #linear regression models\n",
    "import sklearn.model_selection #Separate data for training and evaluation\n",
    "\n",
    "model = linear_model.LinearRegression() #create a linear regression model\n",
    "\n",
    "X = predict_data[[\"count_0\",\"count_1\",\"count_2\",\"count_3\",\"count_4\",\"count_5\",\"period\"]]\n",
    "y = predict_data[\"count_pred\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X,y) #Separate data for training and evaluation\n",
    "model.fit(X_train, y_train) #Feed the model with training data"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T03:31:30.536504Z",
     "iopub.execute_input": "2022-03-18T03:31:30.536817Z",
     "iopub.status.idle": "2022-03-18T03:31:30.562037Z",
     "shell.execute_reply.started": "2022-03-18T03:31:30.536787Z",
     "shell.execute_reply": "2022-03-18T03:31:30.561159Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.score(X_train, y_train))\n",
    "print(model.score(X_test, y_test))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-03-18T03:32:28.644329Z",
     "iopub.execute_input": "2022-03-18T03:32:28.644857Z",
     "iopub.status.idle": "2022-03-18T03:32:28.655685Z",
     "shell.execute_reply.started": "2022-03-18T03:32:28.644818Z",
     "shell.execute_reply": "2022-03-18T03:32:28.654641Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coef = pd.DataFrame({\"feature_names\":X.columns, \"coefficient\":model.coef_})\n",
    "\n",
    "x1=[3,4,4,6,8,7,8]\n",
    "x2=[2,2,3,3,4,6,8]\n",
    "x3=[0,0,0,0,0,0,0]\n",
    "\n",
    "x_pred=[x1,x2,x3]\n",
    "\n",
    "model.predict(x_pred)\n",
    "uselog_months.to_csv(\"use_log_months.csv\",index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}